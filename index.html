---
layout: default
title: ICML Workshop on Stein's Method
---

		<div class="blurb">
			<h1>Workshop on Stein's Method in Machine Learning and Statistics <img src="beach.jpg" alt="beach", width="460", height="280", align="right", style="padding:30px;"></h1>
			<h4>International Conference on Machine Learning 2019</h4>
			<p><strong>Date:</strong> Saturday 15th June 2019.</p> 
			<p><strong>Location:</strong> Long Beach Convention Center.</p>
			
		</div> 

<div class="blurb">

	<h4> Outline </h4>
	<p>Stein's method is a technique from probability theory for bounding the distance between probability measures using differential and difference operators. Although the method was initially designed as a technique for proving central limit theorems, it has recently caught the attention of the machine learning (ML) community and has been used for a variety of practical tasks. Recent applications include goodness-of-fit testing, generative modeling, global non-convex optimisation, variational inference, de novo sampling, constructing powerful control variates for Monte Carlo variance reduction, and measuring the quality of Markov chain Monte Carlo algorithms.</p> 

	<p>Although Stein's method has already had significant impact in ML, most of the applications only scratch the surface of this rich area of research in probability theory. Significant gains could be made by encouraging both communities to interact directly, and this workshop aims to facilitate this discussion.</p>
 
	<p>The workshop will begin with an introduction to Stein's method which will be accessible for researchers in machine learning who are unfamiliar with the topic. It will then consist of an alternating sequence of invited talks from machine learning researchers and experts in Stein's method, which will highlight both foundational topics and applications in machine learning and statistics. The workshop will also include a session for contributed posters and will conclude with a panel discussion to elicit a concise summary of the state of the field. </p>
</div>


<div class="blurb">

	<h4> Timetable </h4>

	<ul>
		<li>8:30-8:45: Overview of the day - Francois-Xavier Briol</li>
		<li>8:45-9:45: Tutorial - Larry Goldstein</li>
		<li>9:45-10:30: Invited Talk - Anima Anandkumar</li>
		<li>10:30-11:00: Break</li>
		<li>11:00-11:45: Invited Talk - Arthur Gretton</li>
		<li>11:45-12:30: Invited Talk - Andrew Duncan</li>
		<li>12:30-13:45: Lunch and Poster Session</li>
		<li>13:45-14:30: Invited Talk - Yinghzen Li</li>
		<li>14:30-15:15: Invited Talk - Ruiyi Zhang</li>
		<li>15:15-15:45: Break</li>
		<li>15:45-16:30: Invited Talk - Paul Valiant</li>
		<li>16:30-17:15: Invited Talk - Louis Chen</li>
		<li>17:15-18:00: Panel Discussion - All speakers</li>
	</ul> 
	
</div>


<div class="blurb">

	<h4> Invited Speakers </h4>

	<ul>

		<li> <strong><a href="http://tensorlab.cms.caltech.edu/users/anima/"> Anima Anandkumar (California Institute of Technology, US)</a></strong>. Anima is Bren Professor in the Department of Computing and Mathematical Sciences at the California Institute of Technology and Director of Machine Learning Research at NVIDIA. She has several papers establishing connections between Stein's method and discriminative learning and tensor methods.</li>

		<li> <strong><a href="http://www.math.nus.edu.sg/~lhychen/"> Louis Chen (National University Singapore, Singapore)</a></strong>. Louis is Emeritus Professor in the Department of Mathematics at the National University of Singapore. On top of his dozens of papers on Stein's method, he has co-authored a book and edited two others on the topic.</li>

		<li> <strong><a href="https://www.turing.ac.uk/people/researchers/andrew-duncan"> Andrew Duncan (Imperial College London, UK)</a></strong>. Andrew is RAEng Assistant Professor in the Department of Mathematics at Imperial College London and group leader for the Data-Centric Engineering Programme at the Alan Turing Institute. Andrew's research applies Stein's method to a variety of problems in ML, including to assessing convergence of MCMC samplers and for learning models with an unnormalised likelihood.</li>

		<li> <strong><a href="http://www.gatsby.ucl.ac.uk/~gretton/"> Arthur Gretton (University College London, UK)</a></strong>. Arthur is Professor at the Gatsby Computational Neuroscience Unit at University College London. He is the author of several papers at the intersection of kernel methods and Stein's method for hypothesis testing, and received a NeurIPS 2017 Best Paper award for a novel approach to goodness-of-fit testing using Stein's method. </li>

		<li> <strong><a href="http://yingzhenli.net/home/en/"> Yingzhen Li (Microsoft Research Cambridge, UK)</a></strong>. Yingzhen is a researcher at Microsoft Research Cambridge, where she works on Bayesian deep learning including graphical models, fast inference methods and uncertainty estimates for downstream tasks. She is particularly interested in connections between Stein's method and gradient estimators for implicit models.  </li>

		<li> <strong><a href="http://cs.brown.edu/~pvaliant/"> Paul Valiant (Brown University, US)</a></strong>. Paul is assistant professor in the department of Computer Science at Brown. He has contributed methodology on particle-based variational inference, and is particular interested in connections with Stein Variational Gradient Descent.  </li>

		<li> <strong><a href="https://users.cs.duke.edu/~ryzhang/"> Ruiyi Zhang (Duke University, US)</a></strong>. Ruiyi is a PhD student in the department of computer science at Duke University. Ruiyi has contributed methodology on particle-based variational inference, and is particular interested in connections with Stein Variational Gradient Descent.  </li>
		

	</ul>

</div>


<div class="blurb">

	<h4> Registration </h4>
	<p>Registration for this workshop is through the main <strong><a href="https://icml.cc/"> ICML website</a></strong>. We encourage participants to register as soon as possible as places are limited and often fill up quickly.</p>

</div>



<div>

	<h4>Organisation</h4>

	<ul>
			<li> <strong><a href="https://fxbriol.github.io/"> Francois-Xavier Briol (University of Cambridge, UK)</a></strong>. Francois-Xavier is a research associate in the Department of Engineering at the University of Cambridge and a visiting researcher at the Alan Turing Institute within the Data-Centric Engineering programme. His research focuses on inference and computation for probabilistic models, and has worked on applications of Stein's method to Bayesian computation. </li>

			<li> <strong><a href="https://web.stanford.edu/~lmackey/"> Lester Mackey (Microsoft Research, US)</a></strong>. Lester is a Researcher at Microsoft Research New England and an Adjunct Professor of Statistics at Stanford University. He has been actively developing Stein's method tools for a variety of problems in machine learning and probabilistic inference including global non-convex optimization, de novo sampling, hypothesis testing, causal inference, and Markov chain Monte Carlo parameter tuning and sampler selection. </li>

			<li> <strong><a href="http://oates.work/"> Chris J. Oates (Newcastle University, UK)</a></strong>. Chris is Chair in Statistics at Newcastle University, UK, and group leader for the Data-Centric Engineering programme at the Alan Turing Institute, UK. His research interests include using Stein's method for posterior computation in the Bayesian statistical context.</li>

			<li> <strong><a href="https://www.cs.utexas.edu/~lqiang/"> Qiang Liu (UT Austin, US)</a></strong>. Qiang is an assistant professor of computer science at UT Austin. His research focuses on probabilistic learning and approximate inference, including application of Stein's method to addressing algorithmic challenges in approximate inference and learning.</li>

			<li> <strong><a href="https://dornsife.usc.edu/larry-goldstein/"> Larry Goldstein (University of Southern California, US)</a></strong>. Larry is Professor of Mathematics at the University of Southern California. His research interests center on Stein's method for distributional approximation and its applications in high dimensional statistical contexts. He is co-author of the 2010 Springer text on 'Normal approximation by Stein's method'.</li>
	</ul>


</div>
					

<div class="blurb">


	<h4> List of Accepted Posters </h4>

	<ol>

	<li> Stein's Method for Error Analysis of Multivariate Density Estimation using Models with Normalizing Flow. </li>

	<li> Stein methods for Robot Navigation. </li> 

	<li> Estimation and Sampling of Unnormalized Statistical Models with Stein Score Matching. </li>  

	<li> Stein’s Method for Policy Gradients Methods in Deep Reinforcement Learning.</li>

	<li> Spectral Estimators for Gradient Fields of Log-Densities.</li>

	<li> Relative Kernel Stein Discrepancy for Multiple Model Comparison.</li>

	<li> Stein Point Markov Chain Monte Carlo.</li>

	<li> Stein’s Lemma for the Reparameterization Trick with Gaussian Mixtures.</li>

	<li> A Stein–Papangelou Goodness-of-Fit Test for Point Processes.</li>

	<li> Adaptive MCMC via combining local samplers.</li>

	<li> To choose or not to choose the Prior. That’s the question!</li>

	<li> Stein Variational Online Changepoint Detection with Applications to Hawkes Processes and Neural Networks. </li>

	<li> Active Domain Randomization. </li>

	<li> Sobolev Descent. </li>

	<li> Yet Another Look at SVGD. </li>

	<li> Multi-Agent Learning Using Malliavin-Stein Variational Gradient Descent. </li>

	<li> Stein's method for computing inverse operators. </li> 

	<li> Using Stein's method to find bounds for the multivariate normal approximation of the group sequential maximum likelihood estimator </li>

	</ol>

</div>